/**
 * GitHub Crawler Source
 * ä» GitHub æŠ“å– AI Agent é¡¹ç›®
 */

import { searchRepos, fetchReadme } from '@/lib/github'
import type { RawAgentData } from './gpt-store'

interface GitHubRepo {
  id: number
  name: string
  full_name: string
  description: string | null
  html_url: string
  stargazers_count: number
  topics: string[]
  owner: {
    login: string
    avatar_url: string
  }
  created_at: string
  updated_at: string
}

export interface CrawlResult {
  success: boolean
  total: number
  created: number
  updated: number
  failed: number
  errors: Array<{ repo: string; error: string }>
}

/**
 * å°† GitHub ä»“åº“è½¬æ¢ä¸º RawAgentData æ ¼å¼
 */
export async function processGitHubRepo(repo: GitHubRepo): Promise<RawAgentData> {
  console.log(`ğŸ“¦ Processing: ${repo.full_name}`)
  
  // è·å– README å†…å®¹
  let readmeContent: string | null = null
  try {
    readmeContent = await fetchReadme(repo.owner.login, repo.name)
  } catch (error) {
    console.warn(`âš ï¸  Failed to fetch README for ${repo.full_name}:`, error)
  }
  
  // æ„å»ºæè¿°ï¼šä¼˜å…ˆä½¿ç”¨ README çš„å‰å‡ æ®µï¼Œå¦åˆ™ä½¿ç”¨ä»“åº“æè¿°
  let description = repo.description || ''
  
  if (readmeContent) {
    // æå– README çš„å‰ 500 ä¸ªå­—ç¬¦ä½œä¸ºåˆå§‹æè¿°
    const cleanReadme = readmeContent
      .replace(/^#.*$/gm, '') // ç§»é™¤æ ‡é¢˜
      .replace(/!\[.*?\]\(.*?\)/g, '') // ç§»é™¤å›¾ç‰‡
      .replace(/\[([^\]]+)\]\([^\)]+\)/g, '$1') // ç§»é™¤é“¾æ¥ä½†ä¿ç•™æ–‡æœ¬
      .trim()
    
    if (cleanReadme.length > 0) {
      description = cleanReadme.substring(0, 500)
    }
  }
  
  return {
    name: repo.name,
    description,
    url: repo.html_url,
    platform: 'GitHub',
    author: repo.owner.login,
    category: inferCategoryFromTopics(repo.topics),
    // GitHub ç‰¹æœ‰å­—æ®µï¼ˆå°†åœ¨ enricher ä¸­å¤„ç†ï¼‰
    github_stars: repo.stargazers_count,
    github_url: repo.html_url,
    github_owner: repo.owner.login,
    github_topics: repo.topics,
    readme_content: readmeContent
  } as RawAgentData & {
    github_stars?: number
    github_url?: string
    github_owner?: string
    github_topics?: string[]
    readme_content?: string | null
  }
}

/**
 * ä» GitHub topics æ¨æ–­åˆ†ç±»
 */
function inferCategoryFromTopics(topics: string[]): string {
  const topicMap: Record<string, string[]> = {
    'development': ['development', 'developer-tools', 'coding', 'programming'],
    'content': ['content', 'writing', 'blog', 'documentation'],
    'data-analysis': ['data', 'analytics', 'data-science', 'visualization'],
    'design': ['design', 'ui', 'ux', 'graphics'],
    'marketing': ['marketing', 'seo', 'advertising'],
    'customer-service': ['customer-service', 'support', 'chatbot'],
    'education': ['education', 'learning', 'tutorial'],
    'research': ['research', 'academic', 'science'],
    'productivity': ['productivity', 'automation', 'workflow']
  }
  
  for (const [category, keywords] of Object.entries(topicMap)) {
    if (topics.some(topic => keywords.includes(topic.toLowerCase()))) {
      return category
    }
  }
  
  return 'other'
}

/**
 * çˆ¬å– GitHub ä»“åº“
 * @param options çˆ¬å–é€‰é¡¹
 * @returns çˆ¬å–ç»“æœ
 */
export async function crawlGitHub(options: {
  topic?: string
  minStars?: number
  maxResults?: number
} = {}): Promise<CrawlResult> {
  const {
    topic = 'ai-agent',
    minStars = 10,
    maxResults = 50
  } = options
  
  console.log('\nğŸš€ Starting GitHub crawler...')
  console.log(`   Topic: ${topic}`)
  console.log(`   Min Stars: ${minStars}`)
  console.log(`   Max Results: ${maxResults}\n`)
  
  const result: CrawlResult = {
    success: true,
    total: 0,
    created: 0,
    updated: 0,
    failed: 0,
    errors: []
  }
  
  try {
    // æœç´¢ä»“åº“
    const repos = await searchRepos({
      topic,
      minStars,
      maxResults,
      sort: 'stars',
      order: 'desc'
    })
    
    result.total = repos.length
    console.log(`\nâœ… Found ${repos.length} repositories\n`)
    
    // å¤„ç†æ¯ä¸ªä»“åº“
    const processedRepos: RawAgentData[] = []
    
    for (const repo of repos) {
      try {
        const rawData = await processGitHubRepo(repo)
        processedRepos.push(rawData)
        result.created++ // æ³¨æ„ï¼šå®é™…çš„ created/updated è®¡æ•°å°†åœ¨ enricher ä¸­ç¡®å®š
        
        // é¿å…è§¦å‘é€Ÿç‡é™åˆ¶
        await new Promise(resolve => setTimeout(resolve, 1000))
      } catch (error) {
        result.failed++
        result.errors.push({
          repo: repo.full_name,
          error: error instanceof Error ? error.message : String(error)
        })
        console.error(`âŒ Failed to process ${repo.full_name}:`, error)
      }
    }
    
    // ç”Ÿæˆçˆ¬å–æŠ¥å‘Š
    console.log('\n' + '='.repeat(60))
    console.log('ğŸ“Š GitHub Crawler Report')
    console.log('='.repeat(60))
    console.log(`Total Repositories Found: ${result.total}`)
    console.log(`Successfully Processed:   ${result.created}`)
    console.log(`Failed:                   ${result.failed}`)
    
    if (result.errors.length > 0) {
      console.log('\nâŒ Errors:')
      result.errors.forEach(({ repo, error }) => {
        console.log(`   - ${repo}: ${error}`)
      })
    }
    
    console.log('='.repeat(60) + '\n')
    
    return result
    
  } catch (error) {
    result.success = false
    console.error('âŒ GitHub crawler failed:', error)
    throw error
  }
}

/**
 * å¯¼å‡ºå¤„ç†åçš„æ•°æ®ä¾› enricher ä½¿ç”¨
 */
export async function crawlAndExport(options: {
  topic?: string
  minStars?: number
  maxResults?: number
} = {}): Promise<RawAgentData[]> {
  const {
    topic = 'ai-agent',
    minStars = 10,
    maxResults = 50
  } = options
  
  console.log('\nğŸš€ Starting GitHub crawler (export mode)...\n')
  
  const repos = await searchRepos({
    topic,
    minStars,
    maxResults,
    sort: 'stars',
    order: 'desc'
  })
  
  const processedRepos: RawAgentData[] = []
  
  for (const repo of repos) {
    try {
      const rawData = await processGitHubRepo(repo)
      processedRepos.push(rawData)
      
      // é¿å…è§¦å‘é€Ÿç‡é™åˆ¶
      await new Promise(resolve => setTimeout(resolve, 1000))
    } catch (error) {
      console.error(`âŒ Failed to process ${repo.full_name}:`, error)
    }
  }
  
  console.log(`\nâœ… Processed ${processedRepos.length} repositories\n`)
  
  return processedRepos
}
